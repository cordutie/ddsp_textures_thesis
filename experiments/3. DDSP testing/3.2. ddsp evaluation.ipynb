{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DDSP Models: Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contain the experiments to evaluate the DDSP models trained in this thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The repository already exists at /home/esteban/Desktop/ddsp_textures_thesis/ddsp_textures.\n"
     ]
    }
   ],
   "source": [
    "#Git clone the ddsp_textures repo in the parent directory if you haven't already\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define the path where you want to clone the repository\n",
    "repo_url = \"https://github.com/cordutie/ddsp_textures.git\"\n",
    "clone_path = os.path.abspath(os.path.join('..', '..', 'ddsp_textures'))\n",
    "\n",
    "# Check if the directory already exists\n",
    "if not os.path.exists(clone_path):\n",
    "    print(f\"Cloning the repository to {clone_path}...\")\n",
    "    subprocess.run([\"git\", \"clone\", repo_url, clone_path])\n",
    "    print(\"Repository cloned successfully.\")\n",
    "else:\n",
    "    print(f\"The repository already exists at {clone_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the ddsp's parent directory to the Python path so that we can import the necessary modules\n",
    "import sys\n",
    "\n",
    "ddsp_dir = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "if ddsp_dir not in sys.path:\n",
    "    sys.path.append(ddsp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddsp_textures.loss.functions import statistics_loss, multiscale_spectrogram_loss\n",
    "import torch\n",
    "\n",
    "def evaluation_multiscale_loss(signal_1, signal_2, frame_size):\n",
    "    #size of signal tensor\n",
    "    size = signal_1.shape[0]\n",
    "    #segmentation\n",
    "    segments_signal_1 = []\n",
    "    segments_signal_2 = []\n",
    "    number_of_frames = size // frame_size\n",
    "    for i in range(0, number_of_frames):\n",
    "        segments_signal_1.append(signal_1[i*frame_size:(i+1)*frame_size])\n",
    "        segments_signal_2.append(signal_2[i*frame_size:(i+1)*frame_size])\n",
    "    losses = []\n",
    "    for i in range(len(segments_signal_1)):\n",
    "        local_loss = multiscale_spectrogram_loss(segments_signal_1[i], segments_signal_2[i])\n",
    "        losses.append(local_loss)\n",
    "        # print(local_loss)\n",
    "    losses_torch = torch.tensor(losses)\n",
    "    losses_mean  = torch.mean(losses_torch) \n",
    "    losses_std   = torch.std(losses_torch) \n",
    "    return losses_mean, losses_std\n",
    "\n",
    "def evaluation_textstat_loss(signal_1, signal_2, frame_size, N_F, erb_bank, log_bank):\n",
    "    #size of signal tensor\n",
    "    size = signal_1.shape[0]\n",
    "    #segmentation\n",
    "    segments_signal_1 = []\n",
    "    segments_signal_2 = []\n",
    "    number_of_frames = size // frame_size\n",
    "    for i in range(0, number_of_frames):\n",
    "        segments_signal_1.append(signal_1[i*frame_size:(i+1)*frame_size])\n",
    "        segments_signal_2.append(signal_2[i*frame_size:(i+1)*frame_size])\n",
    "        \n",
    "    losses = []\n",
    "    for i in range(len(segments_signal_1)):\n",
    "        local_loss = statistics_loss(segments_signal_1[i], segments_signal_2[i], N_F, 44100, erb_bank, log_bank)\n",
    "        losses.append(local_loss)\n",
    "    losses_torch = torch.tensor(losses)\n",
    "    losses_mean  = torch.mean(losses_torch)\n",
    "    losses_std   = torch.std(losses_torch)\n",
    "    return losses_mean, losses_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esteban/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ../data/models/DDSP/long_deep_noreg\n",
      "Multiscale loss mean: 10.975004196166992\n",
      "Multiscale loss std: 1.0862135887145996\n",
      "Textstat loss mean: 0.7756296992301941\n",
      "Textstat loss std: 0.04600538685917854\n",
      "Model: ../data/models/DDSP/small_deep_reg\n",
      "Multiscale loss mean: 6.71328592300415\n",
      "Multiscale loss std: 0.8336761593818665\n",
      "Textstat loss mean: 0.7748166918754578\n",
      "Textstat loss std: 0.05992309749126434\n",
      "Model: ../data/models/DDSP/small_shallow_noreg\n",
      "Multiscale loss mean: 11.136171340942383\n",
      "Multiscale loss std: 1.0861647129058838\n",
      "Textstat loss mean: 0.7837122678756714\n",
      "Textstat loss std: 0.0681658387184143\n",
      "Model: ../data/models/DDSP/long_shallow_reg\n",
      "Multiscale loss mean: 7.2713212966918945\n",
      "Multiscale loss std: 1.0030699968338013\n",
      "Textstat loss mean: 0.7809885740280151\n",
      "Textstat loss std: 0.06261958926916122\n",
      "Model: ../data/models/DDSP/long_shallow_noreg\n",
      "Multiscale loss mean: 10.812215805053711\n",
      "Multiscale loss std: 1.0561673641204834\n",
      "Textstat loss mean: 0.7746486067771912\n",
      "Textstat loss std: 0.0530862882733345\n",
      "Model: ../data/models/DDSP/long_deep_reg\n",
      "Multiscale loss mean: 7.521750450134277\n",
      "Multiscale loss std: 0.9760863780975342\n",
      "Textstat loss mean: 0.7842288613319397\n",
      "Textstat loss std: 0.06276903301477432\n",
      "Model: ../data/models/DDSP/small_shallow_reg\n",
      "Multiscale loss mean: 6.826432704925537\n",
      "Multiscale loss std: 0.8302547335624695\n",
      "Textstat loss mean: 0.7827285528182983\n",
      "Textstat loss std: 0.06029215082526207\n",
      "Model: ../data/models/DDSP/small_depp_noreg\n",
      "Multiscale loss mean: 11.459450721740723\n",
      "Multiscale loss std: 1.0809673070907593\n",
      "Textstat loss mean: 0.7774195075035095\n",
      "Textstat loss std: 0.06390903145074844\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import ddsp_textures.tests.tester as tester\n",
    "import librosa \n",
    "import ddsp_textures.auxiliar.filterbanks as fb\n",
    "\n",
    "# paths of models\n",
    "models_path = \"../data/models/DDSP\"\n",
    "\n",
    "#list of paths of folders inside of the models folder\n",
    "model_folders = []\n",
    "for entry in os.listdir(models_path):\n",
    "    entry_path = os.path.join(models_path, entry)\n",
    "    if os.path.isdir(entry_path):\n",
    "        model_folders.append(entry_path)\n",
    "\n",
    "frame_size_evaluation = 2**15\n",
    "N_filterbank_evaluation = 16\n",
    "erb_bank                            = fb.EqualRectangularBandwidth(frame_size_evaluation, 44100, N_filterbank_evaluation, 20, 44100 // 2)\n",
    "new_frame_size, new_sampling_rate   = frame_size_evaluation // 4, 44100 // 4\n",
    "log_bank                            = fb.Logarithmic(new_frame_size, new_sampling_rate, 6, 10, new_sampling_rate // 4)\n",
    "\n",
    "for model_folder in model_folders:\n",
    "    model, parameters_dict, loss_dict = tester.model_loader(model_folder, print_parameters=False)\n",
    "    og_audio_path          = \"../data/sounds/water_augmented.wav\"\n",
    "    og_audio = librosa.load(og_audio_path, sr=44100)[0]\n",
    "    frame_size         = parameters_dict[\"frame_size\"]\n",
    "    features_annotator = parameters_dict[\"features_annotator\"]\n",
    "    sampling_rate      = parameters_dict[\"sampling_rate\"] \n",
    "    \n",
    "    content_og = tester.audio_preprocess(og_audio_path, frame_size, sampling_rate, features_annotator)\n",
    "    og_resynthesis = tester.model_synthesizer(content_og, model, parameters_dict, random_shift=True)\n",
    "    \n",
    "    og_audio_evaluation_set       = og_audio[60*44100:90*44100]\n",
    "    og_resynthesis_evaluation_set = og_resynthesis[60*44100:90*44100]\n",
    "    \n",
    "    og_audio_evaluation_set_torch       = torch.tensor(og_audio_evaluation_set)\n",
    "    og_resynthesis_evaluation_set_torch = torch.tensor(og_resynthesis_evaluation_set)\n",
    "    \n",
    "    frame_size_evaluation = 2**15\n",
    "    N_filterbank_evaluation = 16\n",
    "    multiscale_loss_mean, multiscale_loss_std = evaluation_multiscale_loss(og_audio_evaluation_set_torch, og_resynthesis_evaluation_set_torch, frame_size_evaluation)\n",
    "    textstat_loss_mean, textstat_loss_std     =   evaluation_textstat_loss(og_audio_evaluation_set_torch, og_resynthesis_evaluation_set_torch, frame_size_evaluation, N_filterbank_evaluation, erb_bank, log_bank)\n",
    "    \n",
    "    print(f\"Model: {model_folder}\")\n",
    "    print(f\"Multiscale loss mean: {multiscale_loss_mean}\")\n",
    "    print(f\"Multiscale loss std: {multiscale_loss_std}\")\n",
    "    print(f\"Textstat loss mean: {textstat_loss_mean}\")\n",
    "    print(f\"Textstat loss std: {textstat_loss_std}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
